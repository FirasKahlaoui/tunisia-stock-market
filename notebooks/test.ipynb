{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the CSV data\n",
    "df = pd.read_csv('./data/cleaned_weekly_stock_market.csv')\n",
    "\n",
    "# Filter the data for \"AMEN BANK\"\n",
    "amen_bank = df[df['companyName'] == 'AMEN BANK']\n",
    "\n",
    "# Extract closing prices\n",
    "amen_bank = amen_bank.reset_index()['closingPrice']\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(np.array(amen_bank).reshape(-1,1))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "training_size = int(len(scaled_data) * 0.70)  # Increase training size\n",
    "test_size = len(scaled_data) - training_size\n",
    "train_data, test_data = scaled_data[0:training_size,:], scaled_data[training_size:len(scaled_data),:1]\n",
    "\n",
    "# Function to create a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - time_step - 1):\n",
    "        a = dataset[i:(i + time_step), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# Create datasets\n",
    "time_step = 15  # Increase time step\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "# Reshape input to be [samples, time steps, features]\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Build the LSTM model with dropout for regularization\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, return_sequences=True, input_shape=(time_step, 1)))\n",
    "model.add(Dropout(0.2))  # Add dropout layer\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(Dropout(0.2))  # Add dropout layer\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=150, batch_size=32, verbose=1)  # Adjust epochs and batch size\n",
    "\n",
    "# Make predictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "# Inverse transform to get actual values\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "\n",
    "# Calculate RMSE\n",
    "train_rmse = math.sqrt(mean_squared_error(y_train, train_predict))\n",
    "test_rmse = math.sqrt(mean_squared_error(y_test, test_predict))\n",
    "print(f\"Train RMSE: {train_rmse}\")\n",
    "print(f\"Test RMSE: {test_rmse}\")\n",
    "\n",
    "# Predict the next 10 days\n",
    "n_steps = time_step\n",
    "x_input = test_data[len(test_data)-n_steps:].reshape(1,-1)\n",
    "temp_input = list(x_input)\n",
    "temp_input = temp_input[0].tolist()\n",
    "\n",
    "lst_output = []\n",
    "for i in range(10):\n",
    "    if len(temp_input) > n_steps:\n",
    "        x_input = np.array(temp_input[1:])\n",
    "        x_input = x_input.reshape(1, -1)\n",
    "        x_input = x_input.reshape((1, n_steps, 1))\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        temp_input = temp_input[1:]\n",
    "        lst_output.extend(yhat.tolist())\n",
    "    else:\n",
    "        x_input = x_input.reshape((1, n_steps,1))\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        lst_output.extend(yhat.tolist())\n",
    "\n",
    "# Plot the last 100 actual values and the predicted values for the next 10 days\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(day_new, scaler.inverse_transform(scaled_data[len(scaled_data)-100:]), label='Actual Values')\n",
    "plt.plot(day_pred, scaler.inverse_transform(lst_output), label='Predicted Values for Next 10 Days')\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Full visualization including all data points and predictions\n",
    "stock_pred = scaled_data.tolist()\n",
    "stock_pred.extend(lst_output)\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(scaler.inverse_transform(stock_pred), label='Full Series with Predictions')\n",
    "plt.title('Full Stock Price Series with Predictions')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
