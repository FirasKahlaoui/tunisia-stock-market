{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forcasting  \n",
    "\n",
    "In this notebook we will predict the closing prices for the next month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Import Libraries\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime, timedelta\n",
    "from copy import deepcopy\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('./data/cleaned_weekly_stock_market.csv')\n",
    "\n",
    "\n",
    "# Extract rows for specified companies\n",
    "companies = ['AMEN BANK', 'ARTES', 'ASSAD', 'BIAT', 'BANQUE DE TUNISIE', 'EURO-CYCLES',\n",
    "             'SOTUMAG', 'ONE TECH', 'SAH', 'SFBT', 'SOMOCER', 'SOTETEL',\n",
    "             'SOTUVER', 'TUNISAIR', 'BANQUE ATTIJARI DE TUNIS', 'TELNET HOLDING', 'TPR', 'UIB']\n",
    "\n",
    "data_filtered = data[data['companyName'].isin(companies)]\n",
    "\n",
    "def str_to_datetime(s):\n",
    "    try:\n",
    "        return datetime.strptime(s, '%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        return datetime.strptime(s, '%d/%m/%Y')\n",
    "def df_to_windowed_df(dataframe, first_date_str, last_date_str, n=3):\n",
    "    # Convert string dates to datetime objects\n",
    "    first_date = str_to_datetime(first_date_str)\n",
    "    last_date = str_to_datetime(last_date_str)\n",
    "    target_date = first_date\n",
    "\n",
    "    dates = []\n",
    "    X, Y = [], []\n",
    "    last_time = False\n",
    "\n",
    "    while not last_time:\n",
    "        # Select the subset of data up to and including the target date\n",
    "        df_subset = dataframe.loc[:target_date].tail(n+1)\n",
    "        if len(df_subset) != n+1:\n",
    "            print(f'Error: Window of size {n} is too large for date {target_date}')\n",
    "            return\n",
    "        \n",
    "        # Extract closing prices as features (X) and target (Y)\n",
    "        values = df_subset['closingPrice'].to_numpy()\n",
    "        x, y = values[:-1], values[-1]\n",
    "\n",
    "        dates.append(target_date)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "\n",
    "        # Attempt to move to the next date within a week\n",
    "        next_week = dataframe.loc[target_date + timedelta(days=1):target_date + timedelta(days=7)]\n",
    "        if not next_week.empty:\n",
    "            next_date = next_week.index[0]\n",
    "        else:\n",
    "            print(\"No more data available for the next week.\")\n",
    "            break\n",
    "\n",
    "        # Update target_date\n",
    "        target_date = next_date\n",
    "\n",
    "        # Check if the process should terminate\n",
    "        if target_date >= last_date:\n",
    "            last_time = True\n",
    "\n",
    "    # Prepare the return DataFrame\n",
    "    ret_df = pd.DataFrame({'Target Date': dates})\n",
    "    X = np.array(X)\n",
    "    for i in range(n):\n",
    "        ret_df[f'Target-{n-i}'] = X[:, i]\n",
    "    ret_df['Target'] = Y\n",
    "\n",
    "    return ret_df\n",
    "\n",
    "\n",
    "def windowed_df_to_date_X_y(windowed_df):\n",
    "    df_as_np = windowed_df.to_numpy()\n",
    "    dates = df_as_np[:, 0]\n",
    "    middle_matrix = df_as_np[:, 1:-1]\n",
    "    X = middle_matrix.reshape(len(dates), middle_matrix.shape[1], 1)\n",
    "    y = df_as_np[:, -1]\n",
    "    return dates, X.astype(np.float32), y.astype(np.float32)\n",
    "\n",
    "def train_and_plot_model(data, company_name):\n",
    "    try:\n",
    "        print(f\"Starting process for {company_name}...\")\n",
    "        n = 3 \n",
    "        df = data[['date', 'closingPrice']]\n",
    "        df['date'] = df['date'].apply(str_to_datetime) \n",
    "        df.index = df.pop('date')\n",
    "        \n",
    "        first_valid_date = df.index[n]\n",
    "        last_date = df.index[-1]\n",
    "        windowed_df = df_to_windowed_df(df, first_valid_date.strftime('%Y-%m-%d'), last_date.strftime('%Y-%m-%d'), n=n)\n",
    "        \n",
    "        if windowed_df is None:\n",
    "            print(\"Windowed dataframe is None, exiting...\")\n",
    "            return\n",
    "\n",
    "        dates, X, y = windowed_df_to_date_X_y(windowed_df)\n",
    "\n",
    "        print(\"Splitting data into train, validation, and test sets...\")\n",
    "       # Define the split indices\n",
    "        q_10 = int(len(dates) * 0.1)\n",
    "        q_20 = int(len(dates) * 0.2)\n",
    "\n",
    "        # Split the data\n",
    "        dates_test, X_test, y_test = dates[:q_10], X[:q_10], y[:q_10]\n",
    "        dates_val, X_val, y_val = dates[q_10:q_20], X[q_10:q_20], y[q_10:q_20]\n",
    "        dates_train, X_train, y_train = dates[q_20:], X[q_20:], y[q_20:]\n",
    "\n",
    "\n",
    "        # Plot the data\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(dates_train, y_train, label='Train')\n",
    "        plt.plot(dates_val, y_val, label='Validation')\n",
    "        plt.plot(dates_test, y_test, label='Test')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'Train, Validation, and Test Data for {company_name}')\n",
    "        plt.show()\n",
    "\n",
    "        model = Sequential([layers.Input(shape=(n, 1)),\n",
    "                            layers.LSTM(64),\n",
    "                            layers.Dense(32, activation='relu'),\n",
    "                            layers.Dense(32, activation='relu'),\n",
    "                            layers.Dense(1)])\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(learning_rate=0.001),\n",
    "                      metrics=['mean_absolute_error'])\n",
    "        model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val))\n",
    "\n",
    "        train_pred = model.predict(X_train).flatten()\n",
    "        val_pred = model.predict(X_val).flatten()\n",
    "        test_pred = model.predict(X_test).flatten()\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(dates_train, train_pred)\n",
    "        plt.plot(dates_train, y_train)\n",
    "        plt.plot(dates_val, val_pred)\n",
    "        plt.plot(dates_val, y_val)\n",
    "        plt.plot(dates_test, test_pred)\n",
    "        plt.plot(dates_test, y_test)\n",
    "        plt.legend(['Training Prediction', 'Training Observation',\n",
    "                    'Validation Prediction', 'Validation Observation',\n",
    "                    'Test Prediction', 'Test Observation'])\n",
    "        plt.title(f'Predictions and Observations for {company_name}')\n",
    "        plt.show()\n",
    "\n",
    "        # Recursive predictions\n",
    "        print(\"Starting recursive predictions...\")\n",
    "        recursive_predictions = []\n",
    "        recursive_dates = np.concatenate([dates_val, dates_test])\n",
    "\n",
    "        last_window = deepcopy(X_train[-1])\n",
    "        for target_date in recursive_dates: \n",
    "            next_pred = model.predict(np.array([last_window])).flatten()\n",
    "            recursive_predictions.append(next_pred)\n",
    "            last_window = np.roll(last_window, -1)\n",
    "            last_window[-1] = next_pred\n",
    "            \n",
    "        recursive_predictions = np.array(recursive_predictions).flatten()\n",
    "        plt.figure(figsize=(19, 6))\n",
    "        plt.plot(dates_train, train_pred)\n",
    "        plt.plot(dates_train, y_train)\n",
    "        plt.plot(dates_val, val_pred)\n",
    "        plt.plot(dates_val, y_val)\n",
    "        plt.plot(dates_test, test_pred)\n",
    "        plt.plot(dates_test, y_test)\n",
    "        plt.plot(recursive_dates, recursive_predictions)\n",
    "        plt.legend(['Training Predictions', \n",
    "                    'Training Observations',\n",
    "                    'Validation Predictions', \n",
    "                    'Validation Observations',\n",
    "                    'Testing Predictions', \n",
    "                    'Testing Observations',\n",
    "                    'Recursive Predictions'])\n",
    "        plt.title(f'Recursive Predictions for {company_name}')\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Apply the model for each company\n",
    "for company in companies:\n",
    "    company_data = data_filtered[data_filtered['companyName'] == company]\n",
    "    if not company_data.empty:\n",
    "        print(f'Training and plotting for {company}')\n",
    "        train_and_plot_model(company_data, company)\n",
    "    else:\n",
    "        print(f'No data available for {company}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime, timedelta\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('./data/cleaned_weekly_stock_market.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract rows for specified companies\n",
    "companies = ['AMEN BANK', 'ARTES', 'ASSAD', 'BIAT', 'BANQUE DE TUNISIE', 'EURO-CYCLES',\n",
    "             'SOTUMAG', 'ONE TECH', 'SAH', 'SFBT', 'SOMOCER', 'SOTETEL',\n",
    "             'SOTUVER', 'TUNISAIR', 'BANQUE ATTIJARI DE TUNIS', 'TELNET HOLDING', 'TPR', 'UIB']\n",
    "\n",
    "data_filtered = data[data['companyName'].isin(companies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_datetime(s):\n",
    "    try:\n",
    "        return datetime.strptime(s, '%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        return datetime.strptime(s, '%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_windowed_df(dataframe, first_date_str, last_date_str, n=3):\n",
    "    # Convert string dates to datetime objects\n",
    "    first_date = str_to_datetime(first_date_str)\n",
    "    last_date = str_to_datetime(last_date_str)\n",
    "    target_date = first_date\n",
    "\n",
    "    dates = []\n",
    "    X, Y = [], []\n",
    "    last_time = False\n",
    "\n",
    "    while not last_time:\n",
    "        # Select the subset of data up to and including the target date\n",
    "        df_subset = dataframe.loc[:target_date].tail(n+1)\n",
    "        if len(df_subset) != n+1:\n",
    "            print(f'Error: Window of size {n} is too large for date {target_date}')\n",
    "            return\n",
    "        \n",
    "        # Extract closing prices as features (X) and target (Y)\n",
    "        values = df_subset['closingPrice'].to_numpy()\n",
    "        x, y = values[:-1], values[-1]\n",
    "\n",
    "        dates.append(target_date)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "\n",
    "        # Attempt to move to the next date within a week\n",
    "        next_week = dataframe.loc[target_date + timedelta(days=1):target_date + timedelta(days=7)]\n",
    "        if not next_week.empty:\n",
    "            next_date = next_week.index[0]\n",
    "        else:\n",
    "            print(\"No more data available for the next week.\")\n",
    "            break\n",
    "\n",
    "        # Update target_date\n",
    "        target_date = next_date\n",
    "\n",
    "        # Check if the process should terminate\n",
    "        if target_date >= last_date:\n",
    "            last_time = True\n",
    "\n",
    "    # Prepare the return DataFrame\n",
    "    ret_df = pd.DataFrame({'Target Date': dates})\n",
    "    X = np.array(X)\n",
    "    for i in range(n):\n",
    "        ret_df[f'Target-{n-i}'] = X[:, i]\n",
    "    ret_df['Target'] = Y\n",
    "\n",
    "    return ret_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrapy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
